; NOTE: Assertions have been autogenerated by test/update_tpde_llc_test_checks.py UTC_ARGS: --version 5
; SPDX-FileCopyrightText: 2025 Contributors to TPDE <https://tpde.org>
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

; RUN: tpde-llc --target=x86_64 %s | %objdump | FileCheck %s -check-prefixes=X64
; RUN: tpde-llc --target=aarch64 %s | %objdump | FileCheck %s -check-prefixes=ARM64

define <2 x float> @fadd_v2f32_1(<2 x float> %0) {
; X64-LABEL: <fadd_v2f32_1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movabs rax, 0x3f8000003f800000
; X64-NEXT:    movq xmm1, rax
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f32_1>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov x16, #0x3f8000003f800000 // =4575657222473777152
; ARM64-NEXT:    fmov d1, x16
; ARM64-NEXT:    fadd v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x float> %0, <float 1.0, float 1.0>
  ret <2 x float> %r
}

define <2 x float> @fadd_v2f32_f32(<2 x float> %0, <2 x float> %1) {
; X64-LABEL: <fadd_v2f32_f32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f32_f32>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x float> %0, %1
  ret <2 x float> %r
}

define <2 x float> @fadd_v2f32_f32_spill(<2 x float> %0, <2 x float> %1) {
; X64-LABEL: <fadd_v2f32_f32_spill>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movq qword ptr [rbp - 0x30], xmm0
; X64-NEXT:    movq qword ptr [rbp - 0x38], xmm1
; X64-NEXT:  <L0>:
; X64-NEXT:    call <L0>
; X64-NEXT:     R_X86_64_PLT32 fadd_v2f32_f32_spill-0x4
; X64-NEXT:    movapd xmm1, xmm0
; X64-NEXT:    addps xmm1, xmmword ptr [rbp - 0x30]
; X64-NEXT:    movq xmm1, qword ptr [rbp - 0x38]
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f32_f32_spill>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    str d0, [x29, #0xa0]
; ARM64-NEXT:    str d1, [x29, #0xa8]
; ARM64-NEXT:    bl 0xc8 <fadd_v2f32_f32_spill+0x18>
; ARM64-NEXT:     R_AARCH64_CALL26 fadd_v2f32_f32_spill
; ARM64-NEXT:    ldr d1, [x29, #0xa0]
; ARM64-NEXT:    fadd v1.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldr d1, [x29, #0xa8]
; ARM64-NEXT:    fadd v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %c = call <2 x float> @fadd_v2f32_f32_spill(<2 x float> %0, <2 x float> %1)
  %a1 = fadd <2 x float> %c, %0
  %a2 = fadd <2 x float> %c, %1
  ret <2 x float> %a2
}

define <4 x float> @fadd_v4f32_1(<4 x float> %0) {
; X64-LABEL: <fadd_v4f32_1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movaps xmm1, xmmword ptr <fadd_v4f32_1+0x13>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v4f32_1>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    adrp x16, 0x0 <.text>
; ARM64-NEXT:     R_AARCH64_ADR_PREL_PG_HI21
; ARM64-NEXT:    ldr q1, [x16]
; ARM64-NEXT:     R_AARCH64_LDST128_ABS_LO12_NC
; ARM64-NEXT:    fadd v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <4 x float> %0, <float 1.0, float 1.0, float 1.0, float 1.0>
  ret <4 x float> %r
}

define <4 x float> @fadd_v4f32_f32(<4 x float> %0, <4 x float> %1) {
; X64-LABEL: <fadd_v4f32_f32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v4f32_f32>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <4 x float> %0, %1
  ret <4 x float> %r
}

define <2 x double> @fadd_v2f64_1(<2 x double> %0) {
; X64-LABEL: <fadd_v2f64_1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movaps xmm1, xmmword ptr <fadd_v2f64_1+0x13>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    addpd xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f64_1>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    adrp x16, 0x0 <.text>
; ARM64-NEXT:     R_AARCH64_ADR_PREL_PG_HI21
; ARM64-NEXT:    ldr q1, [x16]
; ARM64-NEXT:     R_AARCH64_LDST128_ABS_LO12_NC
; ARM64-NEXT:    fadd v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x double> %0, <double 1.0, double 1.0>
  ret <2 x double> %r
}

define <2 x double> @fadd_v2f64_f64(<2 x double> %0, <2 x double> %1) {
; X64-LABEL: <fadd_v2f64_f64>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    addpd xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f64_f64>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x double> %0, %1
  ret <2 x double> %r
}

define <2 x float> @fadd_v2f32_no_salvage_imm(<2 x float> %0) {
; X64-LABEL: <fadd_v2f32_no_salvage_imm>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm1, xmm0
; X64-NEXT:    movabs rax, 0x3f8000003f800000
; X64-NEXT:    movq xmm2, rax
; X64-NEXT:    addps xmm1, xmm2
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f32_no_salvage_imm>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    mov x16, #0x3f8000003f800000 // =4575657222473777152
; ARM64-NEXT:    fmov d1, x16
; ARM64-NEXT:    fadd v1.2s, v0.2s, v1.2s
; ARM64-NEXT:    fadd v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x float> %0, <float 1.0, float 1.0>
  %s = fadd <2 x float> %0, %r
  ret <2 x float> %s
}

define <2 x float> @fadd_v2f32_no_salvage_reg(<2 x float> %0, <2 x float> %1) {
; X64-LABEL: <fadd_v2f32_no_salvage_reg>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    addps xmm2, xmm1
; X64-NEXT:    addps xmm0, xmm2
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f32_no_salvage_reg>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v1.2s, v0.2s, v1.2s
; ARM64-NEXT:    fadd v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x float> %0, %1
  %s = fadd <2 x float> %0, %r
  ret <2 x float> %s
}

define <4 x float> @fadd_v4f32_no_salvage_imm(<4 x float> %0) {
; X64-LABEL: <fadd_v4f32_no_salvage_imm>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm1, xmm0
; X64-NEXT:    movaps xmm2, xmmword ptr <fadd_v4f32_no_salvage_imm+0x17>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    addps xmm1, xmm2
; X64-NEXT:    addps xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v4f32_no_salvage_imm>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    adrp x16, 0x0 <.text>
; ARM64-NEXT:     R_AARCH64_ADR_PREL_PG_HI21
; ARM64-NEXT:    ldr q1, [x16]
; ARM64-NEXT:     R_AARCH64_LDST128_ABS_LO12_NC
; ARM64-NEXT:    fadd v1.4s, v0.4s, v1.4s
; ARM64-NEXT:    fadd v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <4 x float> %0, <float 1.0, float 1.0, float 1.0, float 1.0>
  %s = fadd <4 x float> %0, %r
  ret <4 x float> %s
}

define <4 x float> @fadd_v4f32_no_salvage_reg(<4 x float> %0, <4 x float> %1) {
; X64-LABEL: <fadd_v4f32_no_salvage_reg>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    addps xmm2, xmm1
; X64-NEXT:    addps xmm0, xmm2
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v4f32_no_salvage_reg>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v1.4s, v0.4s, v1.4s
; ARM64-NEXT:    fadd v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <4 x float> %0, %1
  %s = fadd <4 x float> %0, %r
  ret <4 x float> %s
}

define <2 x double> @fadd_v2f64_no_salvage_imm(<2 x double> %0) {
; X64-LABEL: <fadd_v2f64_no_salvage_imm>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm1, xmm0
; X64-NEXT:    movaps xmm2, xmmword ptr <fadd_v2f64_no_salvage_imm+0x17>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    addpd xmm1, xmm2
; X64-NEXT:    addpd xmm0, xmm1
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f64_no_salvage_imm>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    adrp x16, 0x0 <.text>
; ARM64-NEXT:     R_AARCH64_ADR_PREL_PG_HI21
; ARM64-NEXT:    ldr q1, [x16]
; ARM64-NEXT:     R_AARCH64_LDST128_ABS_LO12_NC
; ARM64-NEXT:    fadd v1.2d, v0.2d, v1.2d
; ARM64-NEXT:    fadd v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x double> %0, <double 1.0, double 1.0>
  %s = fadd <2 x double> %0, %r
  ret <2 x double> %s
}

define <2 x double> @fadd_v2f64_no_salvage_reg(<2 x double> %0, <2 x double> %1) {
; X64-LABEL: <fadd_v2f64_no_salvage_reg>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x30
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    addpd xmm2, xmm1
; X64-NEXT:    addpd xmm0, xmm2
; X64-NEXT:    add rsp, 0x30
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <fadd_v2f64_no_salvage_reg>:
; ARM64:         sub sp, sp, #0xa0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    fadd v1.2d, v0.2d, v1.2d
; ARM64-NEXT:    fadd v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xa0
; ARM64-NEXT:    ret
  %r = fadd <2 x double> %0, %1
  %s = fadd <2 x double> %0, %r
  ret <2 x double> %s
}

