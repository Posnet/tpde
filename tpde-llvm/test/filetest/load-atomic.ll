; NOTE: Assertions have been autogenerated by test/update_tpde_llc_test_checks.py UTC_ARGS: --version 5
; SPDX-License-Identifier: LicenseRef-Proprietary

; RUN: tpde-llc --target=x86_64 %s | %objdump | FileCheck %s -check-prefixes=X64
; RUN: tpde-llc --target=aarch64 %s | %objdump | FileCheck %s -check-prefixes=ARM64

define i8 @load_atomic_i8_monotonic(ptr %p) {
; X64-LABEL: <load_atomic_i8_monotonic>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, byte ptr [rdi]
; X64-NEXT:    movzx edi, dil
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i8_monotonic>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrb w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i8, ptr %p monotonic, align 1
  ret i8 %l
}

define i16 @load_atomic_i16_monotonic(ptr %p) {
; X64-LABEL: <load_atomic_i16_monotonic>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, word ptr [rdi]
; X64-NEXT:    movzx edi, di
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i16_monotonic>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldrh w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i16, ptr %p monotonic, align 2
  ret i16 %l
}

define i32 @load_atomic_i32_monotonic(ptr %p) {
; X64-LABEL: <load_atomic_i32_monotonic>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov edi, dword ptr [rdi]
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i32_monotonic>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i32, ptr %p monotonic, align 4
  ret i32 %l
}

define i64 @load_atomic_i64_monotonic(ptr %p) {
; X64-LABEL: <load_atomic_i64_monotonic>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov rdi, qword ptr [rdi]
; X64-NEXT:    mov rax, rdi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i64_monotonic>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldr x0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i64, ptr %p monotonic, align 8
  ret i64 %l
}


define i8 @load_atomic_i8_acquire(ptr %p) {
; X64-LABEL: <load_atomic_i8_acquire>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, byte ptr [rdi]
; X64-NEXT:    movzx edi, dil
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i8_acquire>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldarb w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i8, ptr %p acquire, align 1
  ret i8 %l
}

define i16 @load_atomic_i16_acquire(ptr %p) {
; X64-LABEL: <load_atomic_i16_acquire>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, word ptr [rdi]
; X64-NEXT:    movzx edi, di
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i16_acquire>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldarh w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i16, ptr %p acquire, align 2
  ret i16 %l
}

define i32 @load_atomic_i32_acquire(ptr %p) {
; X64-LABEL: <load_atomic_i32_acquire>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov edi, dword ptr [rdi]
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i32_acquire>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldar w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i32, ptr %p acquire, align 4
  ret i32 %l
}

define i64 @load_atomic_i64_acquire(ptr %p) {
; X64-LABEL: <load_atomic_i64_acquire>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov rdi, qword ptr [rdi]
; X64-NEXT:    mov rax, rdi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i64_acquire>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldar x0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i64, ptr %p acquire, align 8
  ret i64 %l
}


define i8 @load_atomic_i8_seq_cst(ptr %p) {
; X64-LABEL: <load_atomic_i8_seq_cst>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, byte ptr [rdi]
; X64-NEXT:    movzx edi, dil
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i8_seq_cst>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldarb w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i8, ptr %p seq_cst, align 1
  ret i8 %l
}

define i16 @load_atomic_i16_seq_cst(ptr %p) {
; X64-LABEL: <load_atomic_i16_seq_cst>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    movzx edi, word ptr [rdi]
; X64-NEXT:    movzx edi, di
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i16_seq_cst>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldarh w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i16, ptr %p seq_cst, align 2
  ret i16 %l
}

define i32 @load_atomic_i32_seq_cst(ptr %p) {
; X64-LABEL: <load_atomic_i32_seq_cst>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov edi, dword ptr [rdi]
; X64-NEXT:    mov eax, edi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i32_seq_cst>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldar w0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i32, ptr %p seq_cst, align 4
  ret i32 %l
}

define i64 @load_atomic_i64_seq_cst(ptr %p) {
; X64-LABEL: <load_atomic_i64_seq_cst>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    nop word ptr [rax + rax]
; X64-NEXT:    sub rsp, 0x40
; X64-NEXT:    mov rdi, qword ptr [rdi]
; X64-NEXT:    mov rax, rdi
; X64-NEXT:    add rsp, 0x40
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <load_atomic_i64_seq_cst>:
; ARM64:         sub sp, sp, #0xb0
; ARM64-NEXT:    stp x29, x30, [sp]
; ARM64-NEXT:    mov x29, sp
; ARM64-NEXT:    nop
; ARM64-NEXT:    ldar x0, [x0]
; ARM64-NEXT:    ldp x29, x30, [sp]
; ARM64-NEXT:    add sp, sp, #0xb0
; ARM64-NEXT:    ret
  %l = load atomic i64, ptr %p seq_cst, align 8
  ret i64 %l
}
