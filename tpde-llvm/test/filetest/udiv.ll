; NOTE: Assertions have been autogenerated by utils/update_tpde_llvm_test_checks.py UTC_ARGS: --tool tpde_llvm --default-march x86-64-v2 --filter-out "int3" --version 5
; SPDX-FileCopyrightText: 2024 Tobias Schwarz <tobias.schwarz@tum.de>
;
; SPDX-License-Identifier: LicenseRef-Proprietary

; RUN: tpde_llvm %s | llvm-objdump -d -r --no-show-raw-insn --symbolize-operands --no-addresses --x86-asm-syntax=intel - | FileCheck %s -check-prefixes=X64,CHECK --enable-var-scope --dump-input always


define void @udiv_i8_1(i8 %0) {
; X64-LABEL: udiv_i8_1>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x1
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
entry:
  %1 = udiv i8 %0, 1
  ret void
}

define void @udiv_i8_28(i8 %0) {
; X64-LABEL: udiv_i8_28>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x1c
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
entry:
  %1 = udiv i8 %0, 28
  ret void
}

define void @udiv_i8_i8(i8 %0, i8 %1) {
; X64-LABEL: udiv_i8_i8>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    movzx ecx, sil
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i8 %0, %1
  ret void
}

define void @udiv_i8_32(i8 %0) {
; X64-LABEL: udiv_i8_32>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x20
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
entry:
  %1 = udiv i8 %0, 32
  ret void
}

define void @udiv_i16_1(i16 %0) {
; X64-LABEL: udiv_i16_1>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x1
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i16 %0, 1
  ret void
}

define void @udiv_i16_28(i16 %0) {
; X64-LABEL: udiv_i16_28>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x1c
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i16 %0, 28
  ret void
}

define void @udiv_i16_32(i16 %0) {
; X64-LABEL: udiv_i16_32>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    mov rcx, rax
; X64:    xor edx, edx
; X64:    mov ebx, 0x20
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i16 %0, 32
  ret void
}

define void @udiv_i16_i16(i16 %0, i16 %1) {
; X64-LABEL: udiv_i16_i16>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    movzx ecx, si
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
entry:
  %2 = udiv i16 %0, %1
  ret void
}

define void @udiv_i32_1(i32 %0) {
; X64-LABEL: udiv_i32_1>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov ecx, 0x1
; X64:    mov eax, edi
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i32 %0, 1
  ret void
}

define void @udiv_i32_28(i32 %0) {
; X64-LABEL: udiv_i32_28>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov ecx, 0x1c
; X64:    mov eax, edi
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i32 %0, 28
  ret void
}

define void @udiv_i32_32(i32 %0) {
; X64-LABEL: udiv_i32_32>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov ecx, 0x20
; X64:    mov eax, edi
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i32 %0, 32
  ret void
}

define void @udiv_i32_i32(i32 %0, i32 %1) {
; X64-LABEL: udiv_i32_i32>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov eax, edi
; X64:    div esi
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i32 %0, %1
  ret void
}

define void @udiv_i64_1(i64 %0) {
; X64-LABEL: udiv_i64_1>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov rcx, 0x1
; X64:    mov rax, rdi
; X64:    div rcx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i64 %0, 1
  ret void
}

define void @udiv_i64_28(i64 %0) {
; X64-LABEL: udiv_i64_28>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov rcx, 0x1c
; X64:    mov rax, rdi
; X64:    div rcx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i64 %0, 28
  ret void
}

define void @udiv_i64_32(i64 %0) {
; X64-LABEL: udiv_i64_32>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov rcx, 0x20
; X64:    mov rax, rdi
; X64:    div rcx
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %1 = udiv i64 %0, 32
  ret void
}

define void @udiv_i64_i64(i64 %0, i64 %1) {
; X64-LABEL: udiv_i64_i64>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x20
; X64:    xor edx, edx
; X64:    mov rax, rdi
; X64:    div rsi
; X64:    add rsp, 0x20
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i64 %0, %1
  ret void
}

define void @udiv_i8_salvage(i8 %0, i8 %1) {
; X64-LABEL: udiv_i8_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    movzx ecx, sil
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i8 %0, %1
  ret void
}

define void @udiv_i16_salvage(i16 %0, i16 %1) {
; X64-LABEL: udiv_i16_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    movzx ecx, si
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
entry:
  %2 = udiv i16 %0, %1
  ret void
}

define void @udiv_i32_salvage(i32 %0, i32 %1) {
; X64-LABEL: udiv_i32_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov eax, edi
; X64:    div esi
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i32 %0, %1
  ret void
}

define void @udiv_i64_salvage(i64 %0, i64 %1) {
; X64-LABEL: udiv_i64_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x20
; X64:    xor edx, edx
; X64:    mov rax, rdi
; X64:    div rsi
; X64:    add rsp, 0x20
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i64 %0, %1
  ret void
}

define void @udiv_i8_no_salvage(i8 %0, i8 %1) {
; X64-LABEL: udiv_i8_no_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, dil
; X64:    movzx ecx, sil
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    movzx ecx, dil
; X64:    movzx edx, al
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i8 %0, %1
  %3 = udiv i8 %0, %2
  ret void
}

define void @udiv_i16_no_salvage(i16 %0, i16 %1) {
; X64-LABEL: udiv_i16_no_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    push rbx
; X64:    nop dword ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    movzx eax, di
; X64:    movzx ecx, si
; X64:    mov rdx, rax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ebx
; X64:    div ecx
; X64:    movzx ecx, di
; X64:    movzx edx, ax
; X64:    mov rbx, rdx
; X64:    xor edx, edx
; X64:    mov eax, ecx
; X64:    div ebx
; X64:    add rsp, 0x10
; X64:    pop rbx
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rbp + 0x48], dl
entry:
  %2 = udiv i16 %0, %1
  %3 = udiv i16 %0, %2
  ret void
}

define void @udiv_i32_no_salvage(i32 %0, i32 %1) {
; X64-LABEL: udiv_i32_no_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x10
; X64:    xor edx, edx
; X64:    mov eax, edi
; X64:    div esi
; X64:    mov dword ptr [rbp - 0xc], eax
; X64:    xor edx, edx
; X64:    mov eax, edi
; X64:    div dword ptr [rbp - 0xc]
; X64:    add rsp, 0x10
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    add byte ptr [rax], al
entry:
  %2 = udiv i32 %0, %1
  %3 = udiv i32 %0, %2
  ret void
}

define void @udiv_i64_no_salvage(i64 %0, i64 %1) {
; X64-LABEL: udiv_i64_no_salvage>:
; X64:    push rbp
; X64:    mov rbp, rsp
; X64:    nop word ptr [rax + rax]
; X64:    sub rsp, 0x20
; X64:    xor edx, edx
; X64:    mov rax, rdi
; X64:    div rsi
; X64:    mov qword ptr [rbp - 0x18], rax
; X64:    xor edx, edx
; X64:    mov rax, rdi
; X64:    div qword ptr [rbp - 0x18]
; X64:    add rsp, 0x20
; X64:    pop rbp
; X64:    ret
; X64:     ...
; X64:    <unknown>
entry:
  %2 = udiv i64 %0, %1
  %3 = udiv i64 %0, %2
  ret void
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; CHECK: {{.*}}
